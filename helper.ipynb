{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.1.0\n",
      "anyio==4.4.0\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "attrs==24.2.0\n",
      "babel==2.16.0\n",
      "beautifulsoup4==4.12.3\n",
      "bleach==6.1.0\n",
      "certifi==2024.7.4\n",
      "cffi==1.17.0\n",
      "charset-normalizer==3.3.2\n",
      "colorama==0.4.6\n",
      "comm==0.2.2\n",
      "debugpy==1.8.5\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "executing==2.0.1\n",
      "fastjsonschema==2.20.0\n",
      "filelock==3.15.4\n",
      "flatbuffers==24.3.25\n",
      "fqdn==1.5.1\n",
      "fsspec==2024.6.1\n",
      "gast==0.6.0\n",
      "google-pasta==0.2.0\n",
      "grpcio==1.65.4\n",
      "h11==0.14.0\n",
      "h5py==3.11.0\n",
      "httpcore==1.0.5\n",
      "httpx==0.27.0\n",
      "idna==3.7\n",
      "ipykernel==6.29.5\n",
      "ipython==8.26.0\n",
      "ipywidgets==8.1.3\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.4\n",
      "json5==0.9.25\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.10.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter_client==8.6.2\n",
      "jupyter_core==5.7.2\n",
      "jupyter_server==2.14.2\n",
      "jupyter_server_terminals==0.5.3\n",
      "jupyterlab==4.2.4\n",
      "jupyterlab_pygments==0.3.0\n",
      "jupyterlab_server==2.27.3\n",
      "jupyterlab_widgets==3.0.11\n",
      "keras==3.4.1\n",
      "libclang==18.1.1\n",
      "Markdown==3.6\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mistune==3.0.2\n",
      "ml-dtypes==0.4.0\n",
      "mpmath==1.3.0\n",
      "namex==0.0.8\n",
      "nbclient==0.10.0\n",
      "nbconvert==7.16.4\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.3\n",
      "notebook==7.2.1\n",
      "notebook_shim==0.2.4\n",
      "numpy==1.26.4\n",
      "opt-einsum==3.3.0\n",
      "optree==0.12.1\n",
      "overrides==7.7.0\n",
      "packaging==24.1\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pillow==10.4.0\n",
      "platformdirs==4.2.2\n",
      "prometheus_client==0.20.0\n",
      "prompt_toolkit==3.0.47\n",
      "protobuf==4.25.4\n",
      "psutil==6.0.0\n",
      "pure_eval==0.2.3\n",
      "pycparser==2.22\n",
      "Pygments==2.18.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==2.0.7\n",
      "pywin32==306\n",
      "pywinpty==2.0.13\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.1.0\n",
      "qtconsole==5.5.2\n",
      "QtPy==2.4.1\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.7.1\n",
      "rpds-py==0.20.0\n",
      "Send2Trash==1.8.3\n",
      "six==1.16.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.5\n",
      "stack-data==0.6.3\n",
      "sympy==1.13.1\n",
      "tensorboard==2.17.0\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.17.0\n",
      "tensorflow-intel==2.17.0\n",
      "tensorflow-io-gcs-filesystem==0.31.0\n",
      "termcolor==2.4.0\n",
      "terminado==0.18.1\n",
      "tinycss2==1.3.0\n",
      "tornado==6.4.1\n",
      "traitlets==5.14.3\n",
      "types-python-dateutil==2.9.0.20240316\n",
      "typing_extensions==4.12.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.2.2\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.6.0\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "Werkzeug==3.0.3\n",
      "widgetsnbextension==4.0.11\n",
      "wrapt==1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "tf.print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of a + b: 5\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = a + b\n",
    "tf.print(\"Result of a + b:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Model (y = wx + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7\n"
     ]
    }
   ],
   "source": [
    "# A variable (weight) initialized to 0.5. In machine learning models, weights determine the influence of input features on the output.\n",
    "# They are adjusted during training to minimize the error between the predicted and actual values.\n",
    "w = tf.Variable(0.5)  # Initial weight\n",
    "\n",
    "# A constant bias set to 2.0. Bias is an additional parameter in the model that allows it to fit the data better, even when the input is zero.\n",
    "# Unlike weights, the bias is not multiplied by the input, and it helps to shift the output.\n",
    "b = tf.constant(2.0)  # Bias\n",
    "\n",
    "# An input feature, here set to 10.0. Input features are the data fed into the model to make predictions.\n",
    "# In this case, x represents a single feature, but in complex models, there could be multiple input features.\n",
    "x = tf.constant(10.0)  # Input feature (x)\n",
    "\n",
    "# The model calculates the output y using the formula y = wx + b. This is a simple linear model where y is the predicted output.\n",
    "y = w * x + b\n",
    "\n",
    "tf.print(\"Result of y = wx + b:\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop to Adjust the Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom loss function\n",
    "def loss_fn(y_true, y_pred):\n",
    "    # Calculate the difference between the true values (actual labels) and the predicted values\n",
    "    error = y_true - y_pred\n",
    "    \n",
    "    # Square the errors to ensure they are positive (this is part of the Mean Squared Error calculation)\n",
    "    squared_error = tf.square(error)\n",
    "    \n",
    "    # Compute the mean of the squared errors across all examples in the batch\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    \n",
    "    # Return the mean squared error, which represents the loss\n",
    "    return mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "w = tf.Variable(0.5)  # Initial weight\n",
    "b = tf.constant(2.0)  # Bias\n",
    "x = tf.constant(10.0)  # Input feature (x)\n",
    "y = w * x + b\n",
    "tf.print(\"Result of y = wx + b:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Python (Plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "w = 0.5  # Initial weight\n",
    "b = 2.0  # Bias\n",
    "x = 10.0  # Input feature (x)\n",
    "y = w * x + b  # Compute y\n",
    "print(\"Result of y = wx + b:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use TensorFlow?\n",
    "\n",
    "While basic arithmetic operations can be easily performed using standard Python, TensorFlow becomes essential in more complex scenarios, particularly in machine learning and deep learning. Here’s why TensorFlow is useful:\n",
    "\n",
    "**1. Automatic Differentiation and Backpropagation**\n",
    "- TensorFlow can automatically compute derivatives (gradients) of functions, which is crucial for training machine learning models. It efficiently handles backpropagation, allowing the model's parameters to be updated during training.\n",
    "\n",
    "**2. Handling Large-Scale Computations**\n",
    "- TensorFlow is optimized for large-scale numerical computations and can handle operations on large tensors. It leverages hardware acceleration through GPUs and TPUs, making it ideal for performance-intensive tasks.\n",
    "\n",
    "**3. Graph-Based Computation**\n",
    "- TensorFlow allows you to define computational graphs, which is useful for building complex models like neural networks. These graphs enable optimization and deployment on various platforms, enhancing flexibility and scalability.\n",
    "\n",
    "**4. Model Training and Deployment**\n",
    "- TensorFlow provides a comprehensive ecosystem for model training, deployment, and serving. It supports the full lifecycle of a machine learning model, from defining and training the model to saving, loading, and deploying it in production environments.\n",
    "\n",
    "**5. Distributed Computing**\n",
    "- TensorFlow supports distributed computing, enabling the training of models on large datasets across multiple machines or devices. This is crucial for training modern deep learning models on large-scale data efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis of TensorFlow, NumPy, PyTorch, and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **TensorFlow**\n",
    "\n",
    "**Why Use TensorFlow?**\n",
    "\n",
    "- **TensorFlow**: Ideal for scalable, production-ready machine learning models with extensive tools for deployment.\n",
    "\n",
    "**Use Cases:**\n",
    "- Deep learning models (e.g., convolutional neural networks, recurrent neural networks)\n",
    "- Large-scale machine learning projects\n",
    "- Production deployment of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "w = tf.Variable(0.5)  # Initial weight\n",
    "b = tf.constant(2.0)  # Bias\n",
    "x = tf.constant(10.0)  # Input feature (x)\n",
    "y = w * x + b\n",
    "tf.print(\"Result of y = wx + b:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **NumPy**\n",
    "\n",
    "**Why Use NumPy?**\n",
    "\n",
    "- **NumPy**: Best for efficient and simple numerical computations, forming the foundation for other libraries.\n",
    "\n",
    "**Use Cases:**\n",
    "- General-purpose numerical computing\n",
    "- Basic data manipulation and analysis\n",
    "- Lightweight applications that don't require deep learning or GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7.0\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "w = np.array(0.5)  # Initial weight\n",
    "b = np.array(2.0)  # Bias\n",
    "x = np.array(10.0)  # Input feature (x)\n",
    "y = w * x + b  # Compute y\n",
    "print(\"Result of y = wx + b:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **PyTorch**\n",
    "\n",
    "- **PyTorch**: Preferred for research and prototyping due to its flexibility and intuitive debugging.\n",
    "\n",
    "**Use Cases:**\n",
    "- Research and rapid prototyping of deep learning models\n",
    "- Models requiring dynamic computation graphs\n",
    "- Machine learning tasks where flexibility and ease of use are prioritized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7.0\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "w = torch.tensor(0.5)  # Initial weight\n",
    "b = torch.tensor(2.0)  # Bias\n",
    "x = torch.tensor(10.0)  # Input feature (x)\n",
    "y = w * x + b  # Compute y\n",
    "print(\"Result of y = wx + b:\", y.item())  # Use .item() to get the scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **Keras**\n",
    "\n",
    "- **Keras**: Great for beginners and quick prototyping, offering a high-level API integrated with TensorFlow.\n",
    "\n",
    "**Use Cases:**\n",
    "- Beginners learning deep learning concepts\n",
    "- Rapid prototyping of machine learning models\n",
    "- Smaller projects where ease of use is more important than full control over model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of y = wx + b: 7\n"
     ]
    }
   ],
   "source": [
    "# Keras (with TensorFlow backend)\n",
    "w = tf.Variable(0.5)  # Initial weight\n",
    "b = tf.constant(2.0)  # Bias\n",
    "x = tf.constant(10.0)  # Input feature (x)\n",
    "y = w * x + b\n",
    "tf.print(\"Result of y = wx + b:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison Summary**\n",
    "\n",
    "- **TensorFlow vs. PyTorch**: TensorFlow is better suited for large-scale production environments and deployment, while PyTorch is preferred in research and development for its flexibility and ease of use.\n",
    "- **NumPy**: Ideal for basic numerical computations and serves as the foundation for other libraries, but lacks the advanced features needed for machine learning.\n",
    "- **Keras**: Simplifies deep learning with an easy-to-use interface, making it ideal for quick prototyping and learning, but it’s built on top of TensorFlow, so it inherits its strengths and limitations.\n",
    "\n",
    "Each of these libraries has its place in the machine learning ecosystem, and the choice often depends on the specific needs of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_learning_journey_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
